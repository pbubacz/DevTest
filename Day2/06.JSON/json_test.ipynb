{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - JSON mode\n",
    "\n",
    "JSON mode in OpenAI's chat completion allows developers to receive structured data responses in JSON format. \n",
    "This feature is particularly useful for applications that require precise data parsing and integration with other systems. By specifying a JSON schema, developers can guide the model to generate responses that adhere to a predefined structure, ensuring consistency and ease of use when handling complex data interactions. This approach enhances the model's utility in scenarios like API development, data processing, and automated workflows, providing a more reliable and structured output."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use the `import` statement to let our application know that we're going to be using the OpenAI library in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a new `AzureOpenAI` object and pass in the API key and version and the endpoint URL to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "if load_dotenv():\n",
    "    print(\"Found Azure OpenAI API Base Endpoint: \" + os.getenv(\"AZURE_OPENAI_ENDPOINT\"))\n",
    "else: \n",
    "    print(\"Azure OpenAI API Base Endpoint not found. Have you configured the .env file?\")\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    ")\n",
    "def print_response(system_prompt, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"),\n",
    "        messages = [{\"role\" : \"system\", \"content\" : system_prompt}, {\"role\" : \"user\", \"content\" : user_prompt}],\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send a prompt to Azure OpenAI using the OpenAI library\n",
    "\n",
    "Now that we have defined an Azure OpenAI instance, let's try a Chat Completion. We'll call the `chat.completions.create()` method. Note that for the `model` value, we actually pass in the id of our Azure OpenAI `deployment`. We'll also pass the `prompt` we want to use as the `content` of the `messages` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Exercise: Write a prompt that generates the expected completion\n",
    "* Input text:\n",
    "  ```\n",
    "  Hello, my name is Mateo Gomez. I lost my Credit card on August 17th, and I would like to request its cancellation. The last purchase I made was of a Chicken parmigiana dish at Contoso Restaurant, located near the Hollywood Museum, for $40. Below is my personal information for validation:\n",
    "  Profession: Accountant\n",
    "  Social Security number is 123-45-6789\n",
    "  Date of birth: 9-9-1989\n",
    "  Phone number: 949-555-0110\n",
    "  Personal address: 1234 Hollywood Boulevard Los Angeles CA\n",
    "  Linked email account: mateo@contosorestaurant.com\n",
    "  Swift code: CHASUS33XXX\n",
    "  ```\n",
    "* Expected completion:\n",
    "  ```\n",
    "  {\n",
    "      \"reason\": \"Lost card\",\n",
    "      \"classified_reason\": \"lost_card\",\n",
    "      \"name\": \"Mateo Gomez\",\n",
    "      \"ssn\": \"123-45-6789\",\n",
    "      \"dob\": \"09/09/1989\"\n",
    "  }\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"\n",
    "Given an input text containing a customer's personal information and request details, extract and structure the relevant information into a JSON object. \n",
    "The object should include the reason for the request, a classified reason code, and key personal details of the customer. \n",
    "\"\"\"\n",
    "user_prompt =\"\"\" \n",
    "  Hello, my name is Mateo Gomez. I lost my Credit card on August 17th, and I would like to request its cancellation. The last purchase I made was of a Chicken parmigiana dish at Contoso Restaurant, located near the Hollywood Museum, for $40. Below is my personal information for validation:\n",
    "  Profession: Accountant\n",
    "  Social Security Number is 123-45-6789\n",
    "  Date of birth: 9-9-1989\n",
    "  Phone number: 949-555-0110\n",
    "  Personal address: 1234 Hollywood Boulevard Los Angeles CA\n",
    "  Linked email account: mateo@contosorestaurant.com\n",
    "  Swift code: CHASUS33XXX\n",
    "  \"\"\"\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we do better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt =\"\"\" \n",
    "  Hello, my name is Mateo Gomez. I lost my Credit card on August 17th, and I would like to request its cancellation. The last purchase I made was of a Chicken parmigiana dish at Contoso Restaurant, located near the Hollywood Museum, for $40. Below is my personal information for validation:\n",
    "  Profession: Accountant\n",
    "  Social Security Number is 123-45-6789\n",
    "  Phone number: 949-555-0110\n",
    "  Personal address: 1234 Hollywood Boulevard Los Angeles CA\n",
    "  Linked email account: mateo@contosorestaurant.com\n",
    "  Swift code: CHASUS33XXX\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"\n",
    "Given an input text containing a customer's personal information and request details, extract and structure the relevant information into a JSON object. \n",
    "The object should include the reason for the request, a classified reason code, and key personal details of the customer. \n",
    "\n",
    "* Expected completion:\n",
    "\n",
    "  {\n",
    "      \"reason\": \"Lost card\",\n",
    "      \"classified_reason\": \"lost_card\",\n",
    "      \"name\": \"Mateo Gomez\",\n",
    "      \"ssn\": \"123-45-6789\",\n",
    "      \"dob\": \"11/11/1989\"\n",
    "  }\n",
    "\n",
    "\"\"\"\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(system_prompt, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"),\n",
    "        messages = [{\"role\" : \"system\", \"content\" : system_prompt}, {\"role\" : \"user\", \"content\" : user_prompt}],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge: Can you write a prompt that generates the expected completion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"Extract data from the given text\"\"\"\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we do even better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected completion:\n",
    "  ```\n",
    "  {\n",
    "      \"reason\": \"Lost card\",\n",
    "      \"classified_reason\": \"lost_card\",\n",
    "      \"name\": \"Mateo Gomez\",\n",
    "      \"ssn\": \"123-45-6789\",\n",
    "      \"dob\": \"09/09/1989\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "  ## Structured outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"my_schema\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"reason\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"classified_reason\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"ssn\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"dob\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"reason\", \"classified_reason\", \"name\", \"ssn\", \"dob\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(system_prompt, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"),\n",
    "        messages = [{\"role\" : \"system\", \"content\" : system_prompt}, {\"role\" : \"user\", \"content\" : user_prompt}],\n",
    "        response_format=schema\n",
    "\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do the magic!  🪄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"Extract data from the given text\"\"\"\n",
    "print(\"System:\")\n",
    "print(system_prompt)\n",
    "print(\"User:\")\n",
    "print(user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = \"2024-08-01-preview\"\n",
    ")\n",
    "def print_response(system_prompt, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "         model = os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"),\n",
    "        messages = [{\"role\" : \"system\", \"content\" : system_prompt}, {\"role\" : \"user\", \"content\" : user_prompt}],\n",
    "        response_format=schema\n",
    "\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = \"2024-08-01-preview\"\n",
    ")\n",
    "def print_response(system_prompt, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        messages = [{\"role\" : \"system\", \"content\" : system_prompt}, {\"role\" : \"user\", \"content\" : user_prompt}],\n",
    "        response_format=schema\n",
    "\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next magic 🪄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"my_schema\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"reason\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"classified_reason\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"name\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"ssn\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Social Security Number\"\n",
    "                },\n",
    "                \"dob\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Date of Birth\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"reason\", \"classified_reason\", \"name\", \"ssn\", \"dob\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "}\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version = \"2024-08-01-preview\"\n",
    ")\n",
    "def print_response(system_prompt, user_prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o\",\n",
    "        messages = [{\"role\" : \"system\", \"content\" : system_prompt}, {\"role\" : \"user\", \"content\" : user_prompt}],\n",
    "        response_format=schema\n",
    "\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "print_response(system_prompt=system_prompt, user_prompt=user_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
